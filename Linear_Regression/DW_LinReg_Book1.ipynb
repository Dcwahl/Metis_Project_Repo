{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a9a7d4c",
   "metadata": {},
   "source": [
    "# Scraping from IMDB and Box Office Mojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a56ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46d7239",
   "metadata": {},
   "source": [
    "## Gather individual movie URLs from the Top 1000 list \n",
    "Note that IMDB and Box Offie Mojo 'share' urls for individual movies, so the scraping was relatively straightforward on that end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80757cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "pos = 1\n",
    "urls=[]\n",
    "while pos<1000: \n",
    "    urlBase = 'https://www.imdb.com/search/title/?groups=top_1000&sort=user_rating,desc&count=100&start=' + str(pos) +'&ref_=adv_nxt'\n",
    "    #things below!\n",
    "    response = requests.get(urlBase)\n",
    "    if response.status_code != 200:\n",
    "        continue\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page,'lxml')\n",
    "    #soup set-up stuff above\n",
    "    links = soup.find_all('a', href=True)\n",
    "    for i in links:\n",
    "        if re.fullmatch('^\\/title\\/tt[0-9]+\\/', i['href']) and i.text.strip()!='':\n",
    "            #print(i['href']+': '+i.text)\n",
    "            urls.append(i['href'])\n",
    "    pos+=100\n",
    "    time.sleep(np.random.rand()*1.5) #kinda arbitrary amount of time on (0,1.5) in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6089aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing this with a try-except \n",
    "#choice of while loop is because I would like to make sure that the code tries again if the response failed\n",
    "#hence the continue\n",
    "j=0\n",
    "while j<(len(urls)):\n",
    "    try:\n",
    "        title,rating,runtime,budget,color,month,mpaa,genres='','','','','','','','' #initializing all as empty strings\n",
    "        imdbURL = 'https://www.imdb.com' + urls[j]\n",
    "        mojoURL = 'https://www.boxofficemojo.com' + urls[j]\n",
    "        response = requests.get(imdbURL)\n",
    "        if response.status_code !=200:\n",
    "            continue\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page, \"lxml\")\n",
    "        title = soup.find('h1').text.replace(u'\\xa0',' ').strip()\n",
    "        year = title[-5:-1]\n",
    "        title = title[0:-7]\n",
    "        print(title) #temp\n",
    "        rating = soup.find(\"span\",itemprop='ratingValue').text\n",
    "        times = soup.find_all('time')\n",
    "        for i in times:\n",
    "            if re.match('^[0-9]+ min',i.text.strip()):\n",
    "                runtime = i.text.strip()\n",
    "                runtime = runtime.replace(\" min\",\"\")\n",
    "        budget,currency,color = findBudgetBW(soup)\n",
    "        month = findMonth(soup)\n",
    "        #Mojo below\n",
    "        response = requests.get(mojoURL)\n",
    "        if response.status_code !=200:\n",
    "            continue\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page, \"lxml\")\n",
    "        mpaa,genres = findMPAAGenre(soup)\n",
    "        #input into df below\n",
    "        df = df.append({'Title':title,'Rating':rating,'Runtime':runtime,'Budget':currency,'Currency':budget,'BW or Color':color,\n",
    "                       'Month of Release':month,'MPAA':mpaa,'Genre':genres,'Year':year}, ignore_index = True)\n",
    "    except:\n",
    "        #just spit out current state of variables if something fails\n",
    "        quickTest = [title,rating,runtime,budget,color,month,mpaa,genres]\n",
    "        for i in quickTest:\n",
    "            if i is not None:\n",
    "                print(i)\n",
    "    time.sleep(np.random.rand()*1.5)\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb5e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def findBudgetBW(soup): \n",
    "    budget,currency,color = '','',''\n",
    "    searchBase = soup.find_all(\"div\",class_=\"txt-block\")\n",
    "    for i in searchBase:\n",
    "        if \"Budget\" in i.text:\n",
    "            budget= i.text.replace(u'\\n','').replace('Budget:','').replace('(estimated)','').replace(',','').strip()\n",
    "            currency = int(''.join(filter(str.isdigit, budget)))\n",
    "            budget = budget.replace(str(currency),'')\n",
    "        if \"Color\" in i.text:\n",
    "            color = i.text.replace(u'\\n','').replace('Color:','').strip()\n",
    "            colorIndex = color.find(\"Color\")\n",
    "            bwIndex = color.find(\"Black and White\")\n",
    "            if colorIndex==-1 and bwIndex==-1:\n",
    "                color = \"\"\n",
    "            elif (bwIndex==-1 or colorIndex<bwIndex) and colorIndex!=-1:\n",
    "                color = \"Color\"\n",
    "            elif (colorIndex==-1 or bwIndex<colorIndex) and bwIndex!=-1:\n",
    "                color = \"Black and White\"\n",
    "    return budget,currency,color\n",
    " \n",
    "\n",
    "def findMonth(soup):\n",
    "    month = ''\n",
    "    searchBase = soup.find_all('span',class_='attribute')\n",
    "    for i in searchBase:\n",
    "        if re.match('^[0-9]{1,2} [a-zA-Z]+ [0-9]{4}',i.text):\n",
    "            month = re.search('[a-zA-Z]+',i.text)\n",
    "            return month.group(0)\n",
    "    if month =='':\n",
    "        searchBase = soup.find_all('div', class_ = 'txt-block')\n",
    "        for i in searchBase:\n",
    "            match = re.search('[0-9]{1,2} [a-zA-Z]+ [0-9]{4}',i.text)\n",
    "            if match:\n",
    "                string = i.text.replace(\"Release Date:\",\"\").strip() #maybe just add the release date string as condition?\n",
    "                month = re.search('[a-zA-Z]+',string)\n",
    "                return month.group(0)\n",
    "\n",
    "            \n",
    "def findMPAAGenre(soup):\n",
    "    mpaa=''\n",
    "    genre=''\n",
    "    for i in soup.find_all(\"div\", class_=\"a-section a-spacing-none\"):\n",
    "        if 'MPAA' in i.text:\n",
    "            mpaa = i.text.replace('MPAA','').strip()\n",
    "        if 'Genres' in i.text:\n",
    "            genre = i.text.replace('Genres','').replace(u'\\n',\"\").replace(' ','').strip()\n",
    "    return mpaa,genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147dab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading from file\n",
    "#in retrospect, could pickle these but whatever\n",
    "df = pd.to_csv('dataFinal.csv')\n",
    "#df = pd.read_csv('dataFinal.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
